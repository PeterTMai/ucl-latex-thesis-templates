\chapter{Literature review}
\label{chapterlabel4}

\section{Uncertainty}
In order to understand the effects of uncertainty on model prediction, it is important to know the different types of uncertainty and their source. In this section different  uncertainties will be explored.

\subsection{Sources of uncertainty}
There are numerous sources that can produce variability and errors. The different types of sources are shown below:
\begin{description}
\item[Residual variability] Variation due to the process being inherently unpredictable and stochastic. The latter can also be related to model inadequacy (structural uncertainty) due to the lack of details which eventually results in different process values. Usually to account for this variability, an average value is taken over these unrecognized condition to define the true values.
\item[Observational uncertainty] The two sources for this uncertainty stems from either limited or incomplete knowledge and measurement errors. The lack of knowledge can be a result of surrogates of the experiments or due to partial measurements. The measurements error is often attributed to the limited accuracy and resolutions of the sensors.
\item[Parameter uncertainty] The parameters of the model have to be specified in order to predict the behaviour of the process. The choice of the appropriate value of the parameters influences the process values as they can misrepresent the underlying physics.
\item[Condition uncertainty] In differential models, it is important to have initial and boundary conditions before the models is evaluated. These can be obtained from observations or experiments, thus, introduce uncertainties into the models.
\item[Structural (model) uncertainty] Also sometimes called model inadequacy. Models are a simplification of the real-world systems, therefore they are based on a certain number of more or less realistic hypothesis. In addition, some significant phenomena might have been neglected. The predicted values will not be equal to the true value of the process and the discrepancy between the two values is the structural uncertainty. 
\item[Simulator uncertainty] Computational results from a model is accompanied numerical errors associated with grid resolution, time steps,tolerances, convergence and any emulator approximations.
\end{description}

\subsection{Types of uncertainty}
Through identifying the sources of uncertainties, it is possible to classify the if the uncertainty could be reduced or not. The two types of uncertainties are:

\begin{description}
\item[Aleatory uncertainty] Also called statistical, stochastic or irreducible uncertainty, is the uncertainty due to the inherent variation and randomness that can occur in members of population due to spatial and temporal variations. These are typically unbiased and naturally defined using a probabilistic framework.
\item[Epistemic uncertainty] Uncertainty that arises due to simplification, assumptions or the lack of knowledge. Sometimes called reducible or ignorance uncertainty. The uncertainies are often biased and not often defined with a probabilistic network. However with additional knowledge, this uncertainty can be, in principle, eliminated.
\end{description}

\section{Uncertainty quantification methods}
There are several methods to assess the different types of uncertainties and quantify them in a probabilistic framework. In this section the different method of uncertainty quantification will be briefly explained.

\subsection{Input uncertainty}
Input uncertainty arises from uncertain inputs that are used for the model. These input that be either the observational data used in the model or parameter inputs that are determined to fit the model to the data. The uncertain input can be usually defined using a probability density function form the available information.\par

\paragraph{Monte-Carlo}
The Monte-Carlo (MC) algorithm is often used for uncertainty study due to its simplicity and wide-ranging applicability. The algorithm consist from three basic steps:
\begin{enumerate}
    \item A number of samples is drawn from a probability density function.
    \item For each of the drawn samples the model is evaluated.
    \item From the results calculated, the input uncertainty is determined.
\end{enumerate}
In order for the model to converge, a minimum number of samples has to be drawn which is however independent of the number of inputs. However it is important to note that the number of evaluations can be very high making it computationally expensive to run for certain models. 

\paragraph{Polynomial Chaos}
Another method to evaluate the uncertainty is using the polynomial chaos (PC) method. The method uses the polynomial expansion to decompose the model into polynomials. 

\subsection{Model uncertainty}
There are several methods that have been used in the field of computational modelling. The first two methods require a number of observations which are then compared with the model outputs. \par

\paragraph{Model Averaging}
The predictions or probability statements of a number of plausible models are averaged, with weights based either on some measure of model adequacy or some measure of the probability that the model is true. \par

Suppose there are a number of models present for a physical problems. Each model is evaluated using a model selection process, which can be either through Akaike's Information Criterion or Bayes' Information Criterion process. Instead of choosing a single best model, a number of best models are chosen and then a weight is applied and the model results are averaged. \par

\paragraph{Calibration-based methods } 
The focus of this method is on the model discrepancy $\mathbf{\delta} = \textbf{Z} - f(\textbf{X})$ , the discrepancy between the output of a model evaluated at the the true inputs and the true target value. The beliefs about $\mathbf{\delta}$ are updated based on the observations \textbf{Z} and the model is calibrated to minimize the discrepancy. \par

\paragraph{Internal discrepancy}
The model is divided into submodels, where the each submodels are evaluated individually using a method to determine the input uncertainty using one of the methods explained above. \par

The variation of each of submodel is then accounted in the whole model as additional parameter and the sensitivity of each parameter will be evaluated using the methods used to determine the input uncertainty. The parameter term that has the greatest impact on the model would be the most likely to the the most "uncertain". \par


\section{VVUQ in cardiovascular modelling}
In cardiovascular modelling, the process of verification and validation is often interchangable. Furthermore, often the validation process is comparing a single metric such as the outlet pressure or flow with the simulation. \par

While there are srict guidelines for the VVUQ of computational models and methods for UQ, they can be very mathematically very challenging and are often omitted from the analysis. Furthermore, in order to do an accurate analysis of the uncertainty, often a large number of $in vivo$ measurements if often necessary. \par

In the recent year, many of the researches also provide online dataset to establish a standardized dataset for the cardiovascular modelling community. Additionally, there have been also attempts to quantify the error and uncertainty. \par

